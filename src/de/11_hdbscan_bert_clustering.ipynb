{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf9adae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q sentence-transformers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import hdbscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2130037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geclustertes DataFrame laden\n",
    "df = pd.read_excel(\"../../data/df_de_final_duplikate_markiert.xlsx\", engine=\"openpyxl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08aba937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl einzigartiger Fragen: 1316\n"
     ]
    }
   ],
   "source": [
    "# Nur eine Frage pro Duplikat-Gruppe oder alle Einzel-Fragen\n",
    "df_unique = df.drop_duplicates(subset=[\"Duplikat_Gruppe\"], keep=\"first\").copy()\n",
    "\n",
    "print(f\"Anzahl einzigartiger Fragen: {len(df_unique)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943d8828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3c5c0a34394671a47ba3ca1a554ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sentence-BERT Modell laden (multilingual, funktioniert gut auf Deutsch)\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "# Fragetexte vorbereiten\n",
    "texts = df_unique['Frage_Text'].tolist()\n",
    "\n",
    "# Embeddings erzeugen\n",
    "vectors = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bcc6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Distances berechnen (BERT-Embeddings sind normalerweise gut normalisiert)\n",
    "distance_matrix = cosine_distances(vectors).astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "988dce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDBSCAN Clustering\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=2,\n",
    "    min_samples=1,\n",
    "    metric=\"precomputed\",\n",
    "    cluster_selection_epsilon=0.1  # macht HDBSCAN etwas \"weicher\"\n",
    ")\n",
    "labels_hdbscan = clusterer.fit_predict(distance_matrix)\n",
    "\n",
    "# Cluster-Labels in DataFrame speichern\n",
    "df_unique[\"Cluster_HDBSCAN\"] = labels_hdbscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b1f8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl einzigartiger Fragen: 1316\n",
      "Anzahl durch HDBSCAN geclusterter einzigartiger Fragen: 908\n",
      "Effektivität des Clustering (in %): 69.00%\n"
     ]
    }
   ],
   "source": [
    "# Effektivität prüfen: Wie viele einzigartige Fragen wurden sinnvoll geclustert?\n",
    "anzahl_einzigartige = len(df_unique)\n",
    "anzahl_geclusterte_einzigartige = (df_unique[\"Cluster_HDBSCAN\"] != -1).sum()\n",
    "effektivitätsquote = anzahl_geclusterte_einzigartige / anzahl_einzigartige * 100\n",
    "\n",
    "print(f\"Anzahl einzigartiger Fragen: {anzahl_einzigartige}\")\n",
    "print(f\"Anzahl durch HDBSCAN geclusterter einzigartiger Fragen: {anzahl_geclusterte_einzigartige}\")\n",
    "print(f\"Effektivität des Clustering (in %): {effektivitätsquote:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "858680a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering mit BERT erfolgreich abgeschlossen und exportiert.\n"
     ]
    }
   ],
   "source": [
    "# Exportieren\n",
    "df_unique.to_excel(\"../../data/df_de_final_clustered_bert.xlsx\", index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(\"Clustering mit BERT erfolgreich abgeschlossen und exportiert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31e77bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei erfolgreich gespeichert: ../../data/df_de_final_clustered_bert_sorted_with_separators.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# 1. BERT-Cluster-Ergebnis laden\n",
    "df = pd.read_excel(\"../../data/df_de_final_clustered_bert.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "# 2. Nach Cluster sortieren\n",
    "df_sorted = df.sort_values(by=[\"Cluster_HDBSCAN\", \"Frage_Text\"]).reset_index(drop=True)\n",
    "\n",
    "# 3. Neues Workbook erstellen\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"BERT-Cluster sortiert\"\n",
    "\n",
    "# 4. Header schreiben\n",
    "ws.append(df_sorted.columns.tolist())\n",
    "\n",
    "# 5. Farben definieren\n",
    "cluster_fill = PatternFill(start_color=\"D9E1F2\", end_color=\"D9E1F2\", fill_type=\"solid\")  # hellblau für Cluster-Trennung\n",
    "\n",
    "# 6. Cluster schreiben mit visueller Trennung\n",
    "current_cluster = None\n",
    "\n",
    "for idx, row in df_sorted.iterrows():\n",
    "    cluster_id = row[\"Cluster_HDBSCAN\"]\n",
    "    \n",
    "    # Wenn neues Cluster beginnt, füge eine Trennzeile ein\n",
    "    if cluster_id != current_cluster:\n",
    "        if current_cluster is not None:\n",
    "            ws.append([\"\" for _ in range(len(df_sorted.columns))])  # Leere Zeile\n",
    "            for cell in ws[ws.max_row]:\n",
    "                cell.fill = cluster_fill\n",
    "        \n",
    "        current_cluster = cluster_id\n",
    "\n",
    "    # Normale Datenzeile schreiben\n",
    "    ws.append(row.tolist())\n",
    "\n",
    "# 7. Speichern\n",
    "output_path = \"../../data/df_de_final_clustered_bert_sorted_with_separators.xlsx\"\n",
    "wb.save(output_path)\n",
    "\n",
    "print(f\"Datei erfolgreich gespeichert: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d876ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
